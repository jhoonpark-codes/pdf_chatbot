import streamlit as st
import os
import base64
from typing import List, Tuple
from PyPDF2 import PdfReader
from PIL import Image
import io
from openai import AzureOpenAI
from langchain_openai import AzureChatOpenAI
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import AzureOpenAIEmbeddings 
from langchain_community.vectorstores import FAISS
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from langchain.schema import Document
from dotenv import load_dotenv
import warnings
import concurrent.futures
import shutil
import hashlib
import time
import pytesseract
from pdf2image import convert_from_bytes
import fitz  # PyMuPDF
warnings.filterwarnings("ignore")

# Load environment variables
load_dotenv('.env', override=True)

# Azure OpenAI ì„¤ì •
AZURE_OPENAI_API_KEY = os.getenv("AZURE_OPENAI_API_KEY")
AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_DEPLOYMENT_NAME = os.getenv("AZURE_DEPLOYMENT_NAME")
AZURE_OPENAI_API_VERSION = os.getenv("AZURE_OPENAI_API_VERSION")

# Azure OpenAI Embedding ì„¤ì •
AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME = os.getenv("AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME")
AZURE_OPENAI_EMBEDDING_MODEL = os.getenv("AZURE_OPENAI_EMBEDDING_MODEL")
AZURE_OPENAI_EMBEDDING_API_KEY = os.getenv("AZURE_OPENAI_EMBEDDING_API_KEY")
AZURE_OPENAI_EMBEDDING_ENDPOINT = os.getenv("AZURE_OPENAI_EMBEDDING_ENDPOINT")
AZURE_OPENAI_EMBEDDING_API_VERSION = os.getenv("AZURE_OPENAI_EMBEDDING_API_VERSION")

# Azure Computer Vision ì„¤ì • ì¶”ê°€
AZURE_VISION_KEY = os.getenv("AZURE_VISION_KEY")
AZURE_VISION_ENDPOINT = os.getenv("AZURE_VISION_ENDPOINT")

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="PDF ì±—ë´‡", layout="wide")
st.title("PDF ë¬¸ì„œ ê¸°ë°˜ ì±—ë´‡")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "conversation" not in st.session_state:
    st.session_state.conversation = None
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "vector_store" not in st.session_state:
    st.session_state.vector_store = None
if "displayed_images" not in st.session_state:
    st.session_state.displayed_images = []  # í‘œì‹œëœ ì´ë¯¸ì§€ ê¸°ë¡ ì €ì¥

# Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±
client = AzureOpenAI(
    api_key=AZURE_OPENAI_API_KEY,
    api_version=AZURE_OPENAI_API_VERSION,
    azure_endpoint=AZURE_OPENAI_ENDPOINT
)

# ë²¡í„° ì €ì¥ì†Œë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬ ì„¤ì •
VECTOR_STORE_DIR = "vector_store"
if not os.path.exists(VECTOR_STORE_DIR):
    os.makedirs(VECTOR_STORE_DIR)

def encode_image_to_base64(image_bytes: bytes) -> str:
    """ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©"""
    return base64.b64encode(image_bytes).decode('utf-8')

def optimize_image(image_data: bytes, max_size: int = 400) -> bytes:
    """ì´ë¯¸ì§€ ìµœì í™” ê°œì„ """
    try:
        img = Image.open(io.BytesIO(image_data))
        
        # ì´ë¯¸ì§€ í¬ê¸° ì œí•œ
        if max(img.size) > max_size:
            ratio = max_size / max(img.size)
            new_size = tuple(int(dim * ratio) for dim in img.size)
            img = img.resize(new_size, Image.Resampling.LANCZOS)
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”
        if img.mode in ('RGBA', 'LA'):
            background = Image.new('RGB', img.size, (255, 255, 255))
            background.paste(img, mask=img.split()[-1])
            img = background
        
        output = io.BytesIO()
        img.save(output, format='JPEG', quality=60, optimize=True)
        return output.getvalue()
    except Exception as e:
        st.warning(f"ì´ë¯¸ì§€ ìµœì í™” ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return image_data

def time_function(func_name: str):
    """í•¨ìˆ˜ ì‹¤í–‰ ì‹œê°„ì„ ì¸¡ì •"""
    start_time = time.time()
    def get_time():
        return time.time() - start_time
    return get_time

def process_text(reader):
    """í…ìŠ¤íŠ¸ ì²˜ë¦¬"""
    get_time = time_function("í…ìŠ¤íŠ¸ ì²˜ë¦¬")
    contents = []
    for page in reader.pages:
        text = page.extract_text()
        contents.append((text, []))
    return contents, get_time()

def process_images(reader):
    """ì´ë¯¸ì§€ ì²˜ë¦¬"""
    get_time = time_function("ì´ë¯¸ì§€ ì²˜ë¦¬")
    contents = []
    for page in reader.pages:
        images = []
        if '/Resources' in page and '/XObject' in page['/Resources']:
            xObject = page['/Resources']['/XObject'].get_object()
            images = process_images_parallel(page, xObject)
        contents.append(("", images))
    return contents, get_time()

def extract_text_from_image(image):
    """ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (OCR)"""
    try:
        text = pytesseract.image_to_string(image, lang='kor+eng')  # í•œê¸€+ì˜ì–´ ì§€ì›
        return text.strip()
    except Exception as e:
        st.warning(f"OCR ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return ""

def extract_text_with_azure_vision(image_bytes: bytes) -> str:
    """Azure Computer Visionì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        # Computer Vision í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        from azure.cognitiveservices.vision.computervision import ComputerVisionClient
        from msrest.authentication import CognitiveServicesCredentials
        
        computervision_client = ComputerVisionClient(
            AZURE_VISION_ENDPOINT,
            CognitiveServicesCredentials(AZURE_VISION_KEY)
        )
        
        # ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        response = computervision_client.read_in_stream(image_bytes, raw=True)
        operation_location = response.headers["Operation-Location"]
        operation_id = operation_location.split("/")[-1]
        
        # ê²°ê³¼ ëŒ€ê¸°
        import time
        while True:
            result = computervision_client.get_read_result(operation_id)
            if result.status not in ['notStarted', 'running']:
                break
            time.sleep(1)
        
        # í…ìŠ¤íŠ¸ ì¶”ì¶œ
        text = []
        if result.status == "succeeded":
            for text_result in result.analyze_result.read_results:
                for line in text_result.lines:
                    text.append(line.text)
        
        return "\n".join(text)
        
    except Exception as e:
        st.warning(f"Azure Vision OCR ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return ""

def process_pdf(uploaded_file, process_images=False):
    """PDF ì²˜ë¦¬ - ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜µì…˜ ì ìš©"""
    try:
        start_total_time = time.time()
        pdf_bytes = uploaded_file.read()
        contents = []
        
        with st.spinner('PDF ì²˜ë¦¬ ì¤‘...'):
            # PDF ë¡œë“œ
            pdf_document = fitz.open(stream=pdf_bytes, filetype="pdf")
            total_pages = len(pdf_document)
            st.info(f"ì´ {total_pages}í˜ì´ì§€ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
            
            text_start_time = time.time()
            has_content = False
            
            progress_container = st.empty()
            
            for page_num in range(total_pages):
                page = pdf_document[page_num]
                text = page.get_text().strip()
                images = []
                
                # í˜ìŠ¤íŠ¸ê°€ ìˆëŠ” ê²½ìš°
                if text:
                    has_content = True
                    progress_container.info(f"í˜ì´ì§€ {page_num + 1}: {len(text)} ê¸€ì ë°œê²¬")
                
                # ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜µì…˜ì´ ì¼œì ¸ ìˆì„ ë•Œë§Œ ì´ë¯¸ì§€ ì²˜ë¦¬
                if process_images:
                    # í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
                    pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))
                    img_data = pix.tobytes("jpeg")
                    
                    # ì´ë¯¸ì§€ ìµœì í™”
                    try:
                        img = Image.open(io.BytesIO(img_data))
                        img_byte_arr = io.BytesIO()
                        img.save(img_byte_arr, format='JPEG', quality=85, optimize=True)
                        img_data = img_byte_arr.getvalue()
                        img_data = optimize_image(img_data, max_size=1200)
                        
                        img_base64 = encode_image_to_base64(img_data)
                        images.append(img_base64)
                        has_content = True
                        progress_container.info(f"í˜ì´ì§€ {page_num + 1}: ì´ë¯¸ì§€ ì¶”ì¶œ ì™„ë£Œ")
                    except Exception as e:
                        st.warning(f"í˜ì´ì§€ {page_num + 1} ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                
                contents.append((text, images))
                
                # ì§„í–‰ë¥  í‘œì‹œ
                progress_text = f"í˜ì´ì§€ {page_num + 1}/{total_pages} ì²˜ë¦¬ ì¤‘..."
                st.progress((page_num + 1) / total_pages, text=progress_text)
            
            pdf_document.close()
            text_time = time.time() - text_start_time
            
            if not has_content:
                st.error("PDFì—ì„œ ë‚´ìš©ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            total_time = time.time() - start_total_time
            
            # ì²˜ë¦¬ ì‹œê°„ ì •ë³´ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
            st.session_state.processing_times = {
                "text": round(text_time, 2),
                "image": 0,
                "total": round(total_time, 2)
            }
            
            # ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½
            summary = f"""
            PDF ì²˜ë¦¬ ì™„ë£Œ:
            - ì´ {total_pages}í˜ì´ì§€
            - ì²˜ë¦¬ ì‹œê°„: {total_time:.2f}ì´ˆ
            """
            if process_images:
                summary += f"\n- ì´ë¯¸ì§€ ì¶”ì¶œ: {total_pages}ì¥"
            
            st.success(summary)
            
            return contents
            
    except Exception as e:
        import traceback
        st.error(f"PDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        st.error(f"ìƒì„¸ ì˜¤ë¥˜ ì •ë³´:\n```\n{traceback.format_exc()}\n```")
        return None

def analyze_image_content(image_base64: str) -> str:
    """GPT-4 Turboë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ë‚´ìš© ë¶„ì„"""
    try:
        response = client.chat.completions.create(
            model=AZURE_DEPLOYMENT_NAME,  # ê¸°ì¡´ gpt-4o ëª¨ë¸ ìš©
            messages=[
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": "ì´ ì´ë¯¸ì§€ì— ë¬´ì—‡ì„ ë³¼ ìˆ˜ ìˆëŠ”ì§€ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”."
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{image_base64}"
                            }
                        }
                    ]
                }
            ],
            max_tokens=500
        )
        return response.choices[0].message.content
    except Exception as e:
        st.warning(f"ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return ""

def create_vector_store(contents):
    """ë²¡í„° ì €ì¥ì†Œ ìƒì„± - ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜µì…˜ ì ìš©"""
    try:
        documents = []
        with st.spinner('ë¬¸ì„œ ì²˜ë¦¬ ì¤‘...'):
            start_total_time = time.time()
            image_start_time = time.time()
            has_content = False
            
            progress_bar = st.progress(0)
            total_items = len(contents)
            
            for idx, (text, images) in enumerate(contents):
                try:
                    page_content = ""
                    
                    # í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ê²½ìš° ì²˜ë¦¬
                    if text and text.strip():
                        page_content = text.strip()
                        has_content = True
                    
                    # ì´ë¯¸ì§€ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì´ë¯¸ì§€ ë¶„ì„ ìˆ˜í–‰
                    if images:
                        image_descriptions = []
                        for img_idx, image_base64 in enumerate(images):
                            description = analyze_image_content(image_base64)
                            if description:
                                image_descriptions.append(f"Image {img_idx + 1}: {description}")
                                has_content = True
                        
                        if image_descriptions:
                            page_content += "\n\n" if page_content else ""
                            page_content += "Image Descriptions:\n" + "\n".join(image_descriptions)
                    
                    # í˜ì´ì§€ì— ë‚´ìš©ì´ ìˆëŠ” ê²½ìš°ë§Œ ë¬¸ì„œ ì¶”ê°€
                    if page_content:
                        metadata = {
                            "page": idx,
                            "images": images if images else []
                        }
                        documents.append(Document(page_content=page_content, metadata=metadata))
                
                except Exception as e:
                    st.warning(f"í˜ì´ì§€ {idx + 1} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                
                progress_bar.progress((idx + 1) / total_items)
            
            if not has_content:
                st.error("ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            image_time = time.time() - image_start_time
            
            # ì„ë² ë”© ìƒì„±
            try:
                embeddings = AzureOpenAIEmbeddings(
                    deployment=AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME,
                    model=AZURE_OPENAI_EMBEDDING_MODEL,
                    api_key=AZURE_OPENAI_EMBEDDING_API_KEY,
                    azure_endpoint=AZURE_OPENAI_EMBEDDING_ENDPOINT,
                    api_version=AZURE_OPENAI_API_VERSION,
                )
                
                vector_store = FAISS.from_documents(documents, embeddings)
                
                total_time = time.time() - start_total_time
                
                # ì²˜ë¦¬ ì‹œê°„ ì—…ë°ì´íŠ¸
                if "processing_times" in st.session_state:
                    times = st.session_state.processing_times
                    st.session_state.processing_times.update({
                        "image": round(image_time, 2) if any(doc.metadata.get("images") for doc in documents) else 0,
                        "total": round(times["total"] + total_time, 2)
                    })
                
                st.success("ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì™„ë£Œ")
                return vector_store
                
            except Exception as e:
                st.error(f"ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
                return None
            
    except Exception as e:
        st.error(f"ë¬¸ì„œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def initialize_conversation(vector_store):
    llm = AzureChatOpenAI(
        deployment_name=AZURE_DEPLOYMENT_NAME,
        temperature=0,
        azure_endpoint=AZURE_OPENAI_ENDPOINT,
        api_key=AZURE_OPENAI_API_KEY,
        api_version=AZURE_OPENAI_API_VERSION,
    )
    
    memory = ConversationBufferMemory(
        memory_key="chat_history",
        return_messages=True,
        output_key="answer"
    )
    
    conversation = ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=vector_store.as_retriever(),
        memory=memory,
        return_source_documents=True,
        verbose=True
    )
    
    return conversation

def save_vector_store(vector_store, file_name):
    """ë²¡í„° ì €ì¥ì†Œë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
    save_path = os.path.join(VECTOR_STORE_DIR, file_name)
    vector_store.save_local(save_path)
    return save_path

def load_vector_store(file_name, embeddings):
    """ì €ì¥ëœ ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ"""
    load_path = os.path.join(VECTOR_STORE_DIR, file_name)
    if os.path.exists(load_path):
        return FAISS.load_local(load_path, embeddings)
    return None

def delete_vector_store(file_name):
    """ë²¡í„° ì €ì¥ì†Œ ì‚­ì œ"""
    path = os.path.join(VECTOR_STORE_DIR, file_name)
    if os.path.exists(path):
        shutil.rmtree(path)

def process_images_parallel(page, xObject):
    """ì´ë¯¸ì§€ ë³‘ë ¬ ì²˜ë¦¬"""
    images = []
    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
        futures = []
        for obj in xObject:
            if xObject[obj]['/Subtype'] == '/Image':
                futures.append(executor.submit(process_single_image, xObject[obj]))
        
        for future in concurrent.futures.as_completed(futures):
            result = future.result()
            if result:
                images.append(result)
    return images

def process_single_image(image):
    """ë‹¨ì¼ ì´ë¯¸ì§€ ì²˜ë¦¬"""
    try:
        if '/Filter' in image:
            if image['/Filter'] == '/DCTDecode':
                img_data = image._data
            else:
                size = (image['/Width'], image['/Height'])
                img_data = Image.frombytes('RGB', size, image._data)
                img_byte_arr = io.BytesIO()
                img_data.save(img_byte_arr, format='JPEG', quality=60)  # í’ˆì§ˆ ë‚®
                img_data = img_byte_arr.getvalue()
            
            # ì´ë¯¸ì§€ í¬ê¸° ì œí•œ
            img_data = optimize_image(img_data, max_size=400)
            return encode_image_to_base64(img_data)
    except Exception as e:
        st.warning(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def analyze_images_batch(images, batch_size=4):
    """ì´ë¯¸ì§€ ë°°ì¹˜ ë¶„"""
    descriptions = []
    for i in range(0, len(images), batch_size):
        batch = images[i:i + batch_size]
        with concurrent.futures.ThreadPoolExecutor(max_workers=batch_size) as executor:
            futures = [executor.submit(analyze_image_content, img) for img in batch]
            for future in concurrent.futures.as_completed(futures):
                description = future.result()
                if description:
                    descriptions.append(description)
    return descriptions

def analyze_images_in_batch(documents, batch_size=4):
    """ì´ë¯¸ì§€ ë°°ì¹˜ ë¶„ì„"""
    docs_with_images = [doc for doc in documents if doc.metadata.get("images")]
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=batch_size) as executor:
        for i in range(0, len(docs_with_images), batch_size):
            batch = docs_with_images[i:i + batch_size]
            futures = []
            
            for doc in batch:
                for image_base64 in doc.metadata["images"]:
                    futures.append(
                        executor.submit(analyze_image_content, image_base64, doc)
                    )
            
            concurrent.futures.wait(futures)

# ìºì‹œëœ í•¨ìˆ˜ë“¤ ë¨¼ì € ì •ì˜
@st.cache_data(show_spinner=False)
def process_and_cache_image(image_data, image_key, file_hash):
    """ì´ë¯¸ì§€ ì²˜ë¦¬ ê²°ê³¼ ìºì‹œ"""
    try:
        img_data = optimize_image(image_data)
        base64_img = encode_image_to_base64(img_data)
        return base64_img
    except Exception as e:
        st.warning(f"ì´ë¯¸ì§€ ìºì‹œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None

@st.cache_data(show_spinner=False)
def analyze_and_cache_image(image_base64, image_key, file_hash):
    """ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ ìºì‹œ"""
    return analyze_image_content(image_base64)

@st.cache_data(show_spinner=False)
def get_file_hash(file_content: bytes) -> str:
    """íŒŒì¼ ìš© í•´ì‹œê°’ ìƒì„±"""
    return hashlib.md5(file_content).hexdigest()

# ê·¸ ë‹¤ìŒ ìºì‹œ ê´€ë¦¬ í•¨ìˆ˜ ì •ì˜
def clear_cache_for_file(file_name: str):
    """íŠ¹ì • íŒŒì¼ì— ëŒ€í•œ ìºì‹œ ì´ˆê¸°í™”"""
    try:
        # ì´ë¯¸ï¿½ï¿½ï¿½ ì²˜ë¦¬ ìºì‹œ ì´ˆê¸°í™”
        process_and_cache_image.clear()
        # ì´ë¯¸ì§€ ë¶„ì„ ìºì‹œ ì´ˆê¸°í™”
        analyze_and_cache_image.clear()
        # ê¸°íƒ€ ìºì‹œ ì´ˆê¸°í™”
        st.cache_data.clear()
    except Exception as e:
        st.warning(f"ìºì‹œ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

# í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ íŒŒì¼ ì •ë³´
if "current_file_hash" not in st.session_state:
    st.session_state.current_file_hash = None

def get_memory_usage():
    """ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¡°"""
    import psutil
    process = psutil.Process()
    
    # í”„ë¡œì„¸ìŠ¤ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
    process_memory = process.memory_info().rss / 1024 / 1024  # MB ë‹¨ìœ„
    
    # ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì •ë³´
    system_memory = psutil.virtual_memory()
    total_memory = system_memory.total / 1024 / 1024  # MB ë‹¨ìœ„
    available_memory = system_memory.available / 1024 / 1024  # MB ë‹¨ìœ„
    used_memory = system_memory.used / 1024 / 1024  # MB ë‹¨ìœ„
    
    # ìºì‹œ ë©”ëª¨ë¦¬ ì •ë³´ (Linux ì‹œìŠ¤í…œì˜ ê²½ìš°)
    try:
        cached_memory = system_memory.cached / 1024 / 1024  # MB ë‹¨ìœ„
    except:
        cached_memory = 0
    
    return {
        "process": round(process_memory, 2),
        "total": round(total_memory, 2),
        "available": round(available_memory, 2),
        "used": round(used_memory, 2),
        "cached": round(cached_memory, 2)
    }

# í•¨ìˆ˜ë“¤ì„ íŒŒì¼ ìƒë‹¨ìœ¼ë¡œ ì´ë™
def display_processing_times():
    """ì²˜ë¦¬ ì‹œê°„ ì •ë³´ í‘œì‹œ"""
    if "processing_times" in st.session_state:
        times = st.session_state.processing_times
        st.sidebar.subheader("ì²˜ë¦¬ ì‹œê°„")
        
        # ì²˜ë¦¬ ì‹œê°„ í‘œì‹œ
        col1, col2 = st.sidebar.columns(2)
        with col1:
            st.metric("í…ìŠ¤íŠ¸ ì²˜ë¦¬", f"{times['text']}ì´ˆ")
            st.metric("ì´ë¯¸ì§€ ì²˜ë¦¬", f"{times['image']}ì´ˆ")
        with col2:
            st.metric("ì´ ì²˜ë¦¬ ì‹œê°„", f"{times['total']}ì´ˆ")
        
        # ì²˜ë¦¬ ì‹œê°„ ì°¨íŠ¸
        if times['image'] > 0:  # ì´ë¯¸ì§€ ì²˜ë¦¬ê°€ ìˆ˜í–‰ëœ ê²½ìš°ì—ë§Œ
            import plotly.graph_objects as go
            fig = go.Figure(data=[
                go.Bar(name='ì²˜ë¦¬ ì‹œê°„',
                      x=['í…ìŠ¤íŠ¸', 'ì´ë¯¸ì§€', 'ì´ ì‹œê°„'],
                      y=[times['text'], times['image'], times['total']],
                      text=[f"{t:.2f}s" for t in [times['text'], times['image'], times['total']]],
                      textposition='auto')
            ])
            fig.update_layout(
                title="ì²˜ë¦¬ ì‹œê°„ ë¶„ì„",
                height=200,
                showlegend=False
            )
            st.sidebar.plotly_chart(fig, use_container_width=True)

# ì‚¬ì´ë“œë°”: PDF ì—…ë¡œë“œ ë¶€ë¶„ ìˆ˜ì •
with st.sidebar:
    st.header("PDF ë¬¸ì„œ ì„ íƒ")
    
    # PDF ì†ŒìŠ¤ ì„ íƒ
    pdf_source = st.radio(
        "PDF ì†ŒìŠ¤ ì„ íƒ",
        ["ê¸°ë³¸ ë¬¸ì„œ (china_music.pdf)", "íŒŒì¼ ì—…ë¡œë“œ"]
    )
    
    if pdf_source == "íŒŒì¼ ì—…ë¡œë“œ":
        uploaded_file = st.file_uploader("PDF íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”", type="pdf")
        if uploaded_file:
            # íŒŒì¼ í•´ì‹œ ê³„ì‚°
            file_content = uploaded_file.read()
            file_hash = get_file_hash(file_content)
            uploaded_file.seek(0)  # íŒŒì¼ í¬ì¸í„° ë¦¬ì…‹
            
            # ìƒˆë¡œìš´ íŒŒì¼ì´ ì—…ë¡œëœ ê²½ìš° ìºì‹œ ì´ˆê¸°í™”
            if st.session_state.current_file_hash != file_hash:
                clear_cache_for_file(uploaded_file.name)
                st.session_state.current_file_hash = file_hash
    else:
        # ê¸°ë³¸ PDF íŒŒì¼ ê²½ë¡œ í™•ì¸
        default_pdf_path = "./china_music.pdf"
        if not os.path.exists(default_pdf_path):
            st.error("ê¸°ë³¸ PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            uploaded_file = None
        else:
            with open(default_pdf_path, "rb") as f:
                file_content = f.read()
                file_hash = get_file_hash(file_content)
                
                # ê¸°ë³¸ ë¬¸ì„œë¡œ ì „í™˜ ì‹œ ìºì‹œ ì´ˆê¸°í™”
                if st.session_state.current_file_hash != file_hash:
                    clear_cache_for_file("china_music.pdf")
                    st.session_state.current_file_hash = file_hash
            
            uploaded_file = open(default_pdf_path, "rb")
            st.success("ê¸°ë³¸ PDF íŒŒì¼ì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    process_images = st.checkbox("ì´ë¯¸ì§€ ì²˜ë¦¬ í¬í•¨", value=True)
    save_vector = st.checkbox("ë²¡í„° ì €ì¥ì†Œ ì €ì¥", value=False, help="ì²˜ë¦¬ëœ ë²¡í„° ì €ì¥ì†Œë¥¼ íŒŒì¼ë¡œ ì €ì¥í•˜ì—¬ ë‹¤ìŒì— ì¬ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    if uploaded_file and st.button("ì²˜ë¦¬ ì‹œì‘"):
        try:
            # íŒŒì¼ëª…ìœ¼ë¡œ ë²¡í„° ì €ì¥ì†Œ ì‹ë³„ì ìƒì„±
            if pdf_source == "íŒŒì¼ ì—…ë¡œë“œ":
                store_name = uploaded_file.name.replace('.pdf', '')
            else:
                store_name = "china_music"
            
            vector_store = None
            if save_vector:
                # ê¸° ë²¡í„° ì €ì¥ì†Œ í™•ì¸
                embeddings = AzureOpenAIEmbeddings(
                    deployment=AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME,
                    model=AZURE_OPENAI_EMBEDDING_MODEL,
                    api_key=AZURE_OPENAI_EMBEDDING_API_KEY,
                    azure_endpoint=AZURE_OPENAI_EMBEDDING_ENDPOINT,
                    api_version=AZURE_OPENAI_API_VERSION,
                )
                vector_store = load_vector_store(store_name, embeddings)
            
            # ë²¡í„° ì €ì¥ì†Œê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
            if vector_store is None:
                contents = process_pdf(uploaded_file, process_images)
                if contents:
                    vector_store = create_vector_store(contents)
                    if vector_store and save_vector:
                        # ë²¡í„° ì €ì¥ì†Œ ì €ì¥
                        save_vector_store(vector_store, store_name)
                        st.success(f"ë²¡í„° ì €ì¥ì†Œê°€ '{store_name}' ì´ë¦„ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            if vector_store:
                st.session_state.vector_store = vector_store
                st.session_state.conversation = initialize_conversation(vector_store)
                st.success("PDF ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.session_state.chat_history = []
                
                # ì²˜ë¦¬ ì‹œê°„ í‘œì‹œ
                display_processing_times()
                
        finally:
            if pdf_source == "ê¸°ë³¸ ë¬¸ì„œ (china_music.pdf)" and uploaded_file:
                uploaded_file.close()

    # ì €ì¥ëœ ë²¡í„° ì €ì¥ì†Œê°€ ìˆì„ ë•Œë§Œ ì´ˆê¸°í™” ë²„íŠ¼ í‘œì‹œ
    if os.path.exists(os.path.join(VECTOR_STORE_DIR, "china_music")) or \
       (pdf_source == "íŒŒì¼ ì—…ë¡œë“œ" and uploaded_file and 
        os.path.exists(os.path.join(VECTOR_STORE_DIR, uploaded_file.name.replace('.pdf', '')))):
        if st.button("ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™”"):
            if pdf_source == "íŒŒì¼ ì—…ë¡œë“œ" and uploaded_file:
                store_name = uploaded_file.name.replace('.pdf', '')
            else:
                store_name = "china_music"
            delete_vector_store(store_name)
            st.session_state.vector_store = None
            st.session_state.conversation = None
            st.session_state.chat_history = []
            st.success("ë²¡í„° ì €ì¥ì†Œê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

    if st.sidebar.checkbox("ë””ë²„ê·¸ ì •ë³´ í‘œì‹œ"):
        import psutil
        process = psutil.Process()
        st.sidebar.info(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {process.memory_info().rss / 1024 / 1024:.2f} MB")
        st.sidebar.info(f"í˜„ì¬ íŒŒì¼: {st.session_state.current_file_hash}")

    if st.checkbox("ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§", value=False):
        memory_info = get_memory_usage()
        
        st.subheader("ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰")
        col1, col2 = st.columns(2)
        
        with col1:
            st.metric("í”„ë¡œì„¸ìŠ¤", f"{memory_info['process']} MB")
            st.metric("ì‚¬ìš© ê°€ëŠ¥", f"{memory_info['available']} MB")
            st.metric("ìºì‹œ", f"{memory_info['cached']} MB")
        
        with col2:
            st.metric("ì „ì²´", f"{memory_info['total']} MB")
            st.metric("ì‚¬ìš© ì¤‘", f"{memory_info['used']} MB")
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì°¨íŠ¸
        import plotly.graph_objects as go
        
        fig = go.Figure(go.Pie(
            values=[memory_info['available'], memory_info['used'], memory_info['cached']],
            labels=['ì‚¬ìš© ê°€ëŠ¥', 'ì‚¬ìš© ì¤‘', 'ìºì‹œ'],
            hole=.3
        ))
        fig.update_layout(
            title="ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¶„í¬",
            showlegend=True,
            height=300
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # ìºì‹œëœ ì´ë¯¸ì§€ ìˆ˜
        cached_items = len(st.session_state.keys())
        st.metric("ìºì‹œëœ í•­ëª© ìˆ˜", cached_items)
        
        if st.button("ìºì‹œ ë¹„ìš°ê¸°"):
            st.cache_data.clear()
            st.experimental_rerun()

# ìë™ ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ (30ì´ˆë§ˆë‹¤ ê°±ì‹ )
if "monitor_memory" not in st.session_state:
    st.session_state.monitor_memory = False

if st.session_state.monitor_memory:
    import time
    
    placeholder = st.empty()
    while True:
        with placeholder.container():
            memory_info = get_memory_usage()
            st.metric("í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰", f"{memory_info['process']} MB")
        time.sleep(30)

# ë©”ì¸ í™”ë©´: ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ ë¶€ë¶„ ìˆ˜ì •
if st.session_state.conversation is None:
    st.info("ğŸ‘ˆ ì‹œì‘í•˜ë ¤ë©´ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
else:
    chat_container = st.container()
    with chat_container:
        # ì±„íŒ… ê¸°ë¡ í‘œì‹œ
        for message in st.session_state.chat_history:
            if isinstance(message, tuple):
                user_message, bot_message = message
                with st.chat_message("user"):
                    st.write(user_message)
                with st.chat_message("assistant"):
                    st.write(bot_message)
                    
        # ì €ì¥ëœ ì´ë¯¸ì§€ í‘œì‹œ
        for image_data in st.session_state.displayed_images:
            with st.chat_message("assistant"):
                st.info(image_data["caption"])
                image = Image.open(io.BytesIO(base64.b64decode(image_data["image"])))
                st.image(image, caption=image_data["index"], use_column_width=True)
    
    # ì‚¬ìš©ì ì…ë ¥
    user_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")
    if user_input:
        with st.chat_message("user"):
            st.write(user_input)
        
        with st.chat_message("assistant"):
            with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                response = st.session_state.conversation({"question": user_input})
                st.write(response["answer"])
                
                if process_images:
                    displayed_images_count = 0  # í‘œì‹œëœ ì´ë¯¸ì§€ ìˆ˜ ì¶”ì 
                    for doc in response.get("source_documents", []):
                        if doc.metadata.get("images") and displayed_images_count < 2:  # ìµœëŒ€ 2ê°œê¹Œì§€ë§Œ ì²˜ë¦¬
                            st.info("ì´ ë‹µë³€ê³¼ ê´€ë ¨ëœ ì´ë¯¸ì§€:")
                            for idx, image_base64 in enumerate(doc.metadata["images"]):
                                if displayed_images_count >= 2:  # 2ê°œ ì´ìƒì´ë©´ ì¤‘ë‹¨
                                    break
                                try:
                                    image_bytes = base64.b64decode(image_base64)
                                    image = Image.open(io.BytesIO(image_bytes))
                                    st.image(image, caption=f"ê´€ë ¨ ì´ë¯¸ì§€ {displayed_images_count + 1}", use_column_width=True)
                                    
                                    # ì´ë¯¸ì§€ ì •ë³´ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                                    st.session_state.displayed_images.append({
                                        "image": image_base64,
                                        "caption": "ì´ ë‹µë³€ê³¼ ê´€ë ¨ëœ ì´ë¯¸ì§€:",
                                        "index": f"ê´€ë ¨ ì´ë¯¸ì§€ {displayed_images_count + 1}"
                                    })
                                    displayed_images_count += 1
                                except Exception as e:
                                    st.warning(f"ì´ë¯¸ì§€ í‘œï¿½ï¿½ï¿½ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                                    
                    if displayed_images_count == 2:  # 2ê°œê°€ í‘œì‹œëœ ê²½ìš° ë©”ì‹œì§€ í‘œì‹œ
                        st.info("(ìµœëŒ€ 2ê°œì˜ ê´€ë ¨ ì´ë¯¸ì§€ë§Œ í‘œì‹œë©ë‹ˆë‹¤)")
        
        # ì±„íŒ… ê¸°ë¡ ì €ì¥
        st.session_state.chat_history.append((user_input, response["answer"]))

def create_optimized_vector_store(documents, embeddings):
    """ìµœì í™”ëœ ë²¡í„° ì €ì¥ì†Œ ìƒì„±"""
    # ë¬¸ì„œë¥¼ ë°°ì¹˜ë¡œ ì²˜ë¦¬
    batch_size = 32
    vector_store = None
    
    for i in range(0, len(documents), batch_size):
        batch = documents[i:i + batch_size]
        if vector_store is None:
            vector_store = FAISS.from_documents(batch, embeddings)
        else:
            batch_store = FAISS.from_documents(batch, embeddings)
            vector_store.merge_from(batch_store)
    
    return vector_store

def create_embeddings_batch(texts: List[str], embeddings: AzureOpenAIEmbeddings, batch_size: int = 16):
    """ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì„ë² ë”© ìƒì„±"""
    all_embeddings = []
    for i in range(0, len(texts), batch_size):
        batch = texts[i:i + batch_size]
        batch_embeddings = embeddings.embed_documents(batch)
        all_embeddings.extend(batch_embeddings)
    return all_embeddings

def optimize_document_content(documents: List[Document]):
    """ë¬¸ì„œ ë‚´ìš© ìµœì í™”"""
    for doc in documents:
        # í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ
        if len(doc.page_content) > 1000:
            doc.page_content = doc.page_content[:1000]
        
        # ì´ë¯¸ì§€ í¬ê¸° ì œí•œ
        if doc.metadata.get("images"):
            doc.metadata["images"] = [
                optimize_image_base64(img) for img in doc.metadata["images"]
            ]
    return documents

def create_documents_parallel(contents):
    """ë³‘ë ¬ë¡œ ë¬¸ì„œ ìƒì„±"""
    documents = []
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,
        chunk_overlap=50,
        length_function=len,
        separators=["\n\n", "\n", " ", ""]
    )
    
    def process_content(idx, text, images):
        if not text.strip():
            return []
        
        chunks = splitter.split_text(text)
        return [
            Document(
                page_content=chunk,
                metadata={
                    "page": idx,
                    "chunk": chunk_num,
                    "images": images if images else []
                }
            )
            for chunk_num, chunk in enumerate(chunks)
        ]
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
        futures = [
            executor.submit(process_content, idx, text, images)
            for idx, (text, images) in enumerate(contents)
        ]
        
        with st.progress(0) as progress_bar:
            for idx, future in enumerate(concurrent.futures.as_completed(futures)):
                documents.extend(future.result())
                progress_bar.progress((idx + 1) / len(futures))
    
    return documents
